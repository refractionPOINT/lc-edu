<htmL>
    <head>
        <link rel="stylesheet" href="../style.css">
    </head>
    <body>
        <div class="container">
            <iframe width="670" height="377" src="https://www.youtube.com/embed/q3JsE2NtSOU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

            Firehose
The Firehose is a simple object that listens on a port for LimaCharlie.io data. Under the hood it creates a Syslog Output on limacharlie.io pointing to itself and removes it on shutdown. Data from limacharlie.io is added to firehose.queue (a gevent Queue) as it is received.

It is a basic building block of automation for limacharlie.io.

python -m limacharlie.Firehose 1.2.3.4:9424 event -n firehose_test -t fh_test --oid c82e5c17-d519-4ef5-a4ac-caa4a95d31ca

Listens on interface 1.2.3.4, port 9424 for incoming connections from LimaCharlie.io. Receives only events from hosts tagged with fh_test.

Spout
Much like the Firehose, the Spout receives data from LimaCharlie.io, the difference is that the Spout does not require opening a local port to listen actively on. Instead it leverages stream.limacharlie.io to receive the data stream over HTTPS.

A Spout is automatically created when you instantiate a Manager with the is_interactive = True and inv_id = XXXX arguments in order to provide real-time feedback from tasking sensors.

python -m limacharlie.Spout event --oid c82e5c17-d519-4ef5-a4ac-caa4a95d31ca

Behaves similarly to the Firehose, but instead of listenning from an internet accessible port, it connects to the stream.limacharlie.io service to stream the output over HTTPS. This means the Spout allows you to get ad-hoc output like the Firehose, but it also works through NATs and proxies.

It is MUCH more convenient for short term ad-hoc outputs, but it is less reliable than a Firehose for very large amounts of data.
        
    </div>
    </body>
</htmL>